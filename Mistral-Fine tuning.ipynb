{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"gpuType":"T4","authorship_tag":"ABX9TyPbCCFGsakm1Y0xVjhUnUWP"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"widgets":{"application/vnd.jupyter.widget-state+json":{"e538b298684d42118237b7d42847800a":{"model_module":"@jupyter-widgets/controls","model_name":"VBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"VBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"VBoxView","box_style":"","children":["IPY_MODEL_fa7f2ccd1c2c4e15a7a3735e1e2a8b78","IPY_MODEL_313eb32858304222b82620a8ad43de26","IPY_MODEL_e66adf54917d4af8a1daea451b2cb286","IPY_MODEL_ebe04aa0f5f94e3e8133533e1b976d01"],"layout":"IPY_MODEL_1bd2bd6c2dd24f9dbaee14ed15c67f4d"}},"2ff9b790c63043e99dccd1a0be98278f":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_d72bc7c145e54e15898de403a760d5c4","placeholder":"​","style":"IPY_MODEL_06289b2fdc834a2fb91f1c82c9289c59","value":"<center> <img\nsrc=https://huggingface.co/front/assets/huggingface_logo-noborder.svg\nalt='Hugging Face'> <br> Copy a token from <a\nhref=\"https://huggingface.co/settings/tokens\" target=\"_blank\">your Hugging Face\ntokens page</a> and paste it below. <br> Immediately click login after copying\nyour token or it might be stored in plain text in this notebook file. </center>"}},"61f083dd5eda4c41bea992900f27b750":{"model_module":"@jupyter-widgets/controls","model_name":"PasswordModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"PasswordModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"PasswordView","continuous_update":true,"description":"Token:","description_tooltip":null,"disabled":false,"layout":"IPY_MODEL_6f10e2e2e453485e9cb6f00adcc275d6","placeholder":"​","style":"IPY_MODEL_025c641c62d3402896f704a549fb75c6","value":""}},"1fd9ca95b8bb4a088bd9e2989ae06db3":{"model_module":"@jupyter-widgets/controls","model_name":"CheckboxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"CheckboxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"CheckboxView","description":"Add token as git credential?","description_tooltip":null,"disabled":false,"indent":true,"layout":"IPY_MODEL_1a036fb7a56b49a0b5e123ab7852d2a7","style":"IPY_MODEL_5aa0e23fb9e04e69bd5bac8779ffa13a","value":true}},"ccf72b0e4a6543bbabc898eb99fc2d2b":{"model_module":"@jupyter-widgets/controls","model_name":"ButtonModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ButtonModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ButtonView","button_style":"","description":"Login","disabled":false,"icon":"","layout":"IPY_MODEL_e338f306e7d2410f8bfac27858b694d4","style":"IPY_MODEL_fa1178e6fd0242edbf4ff6fcfb661f3f","tooltip":""}},"606c311aaba24352b609e58c6a5af634":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_e7a3df4ae5c84181874080f3772ddb88","placeholder":"​","style":"IPY_MODEL_58d9fc7476ab4d328fb455b2d9edccac","value":"\n<b>Pro Tip:</b> If you don't already have one, you can create a dedicated\n'notebooks' token with 'write' access, that you can then easily reuse for all\nnotebooks. </center>"}},"1bd2bd6c2dd24f9dbaee14ed15c67f4d":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":"center","align_self":null,"border":null,"bottom":null,"display":"flex","flex":null,"flex_flow":"column","grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":"50%"}},"d72bc7c145e54e15898de403a760d5c4":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"06289b2fdc834a2fb91f1c82c9289c59":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"6f10e2e2e453485e9cb6f00adcc275d6":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"025c641c62d3402896f704a549fb75c6":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"1a036fb7a56b49a0b5e123ab7852d2a7":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"5aa0e23fb9e04e69bd5bac8779ffa13a":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"e338f306e7d2410f8bfac27858b694d4":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"fa1178e6fd0242edbf4ff6fcfb661f3f":{"model_module":"@jupyter-widgets/controls","model_name":"ButtonStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ButtonStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","button_color":null,"font_weight":""}},"e7a3df4ae5c84181874080f3772ddb88":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"58d9fc7476ab4d328fb455b2d9edccac":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"a4d20611f8404ce78d68e6d35900f088":{"model_module":"@jupyter-widgets/controls","model_name":"LabelModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"LabelModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"LabelView","description":"","description_tooltip":null,"layout":"IPY_MODEL_f4d94a91813f412b9c25f0c8aa2636df","placeholder":"​","style":"IPY_MODEL_26826a106cc342f897a1f74c67e51a50","value":"Connecting..."}},"f4d94a91813f412b9c25f0c8aa2636df":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"26826a106cc342f897a1f74c67e51a50":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"fa7f2ccd1c2c4e15a7a3735e1e2a8b78":{"model_module":"@jupyter-widgets/controls","model_name":"LabelModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"LabelModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"LabelView","description":"","description_tooltip":null,"layout":"IPY_MODEL_52470aaa1caf4c8a8b6cfbb4e19a0d30","placeholder":"​","style":"IPY_MODEL_6eddb37a7769466d9259d0730b112740","value":"Token is valid (permission: write)."}},"313eb32858304222b82620a8ad43de26":{"model_module":"@jupyter-widgets/controls","model_name":"LabelModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"LabelModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"LabelView","description":"","description_tooltip":null,"layout":"IPY_MODEL_d6089d0077634d0e8b39d0adc220bfbb","placeholder":"​","style":"IPY_MODEL_4d8789a7d65a4a7bb7624f6c076df23f","value":"Your token has been saved in your configured git credential helpers (store)."}},"e66adf54917d4af8a1daea451b2cb286":{"model_module":"@jupyter-widgets/controls","model_name":"LabelModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"LabelModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"LabelView","description":"","description_tooltip":null,"layout":"IPY_MODEL_252a6e2c165d4847be467a4568f94ec4","placeholder":"​","style":"IPY_MODEL_f8be22472b7e429dbd745417545a97ad","value":"Your token has been saved to /root/.cache/huggingface/token"}},"ebe04aa0f5f94e3e8133533e1b976d01":{"model_module":"@jupyter-widgets/controls","model_name":"LabelModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"LabelModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"LabelView","description":"","description_tooltip":null,"layout":"IPY_MODEL_b9ad0304df3a4e80a3b77c0f67da7fe1","placeholder":"​","style":"IPY_MODEL_9c73c4b5e1124fae87034864c38ddff3","value":"Login successful"}},"52470aaa1caf4c8a8b6cfbb4e19a0d30":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"6eddb37a7769466d9259d0730b112740":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"d6089d0077634d0e8b39d0adc220bfbb":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"4d8789a7d65a4a7bb7624f6c076df23f":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"252a6e2c165d4847be467a4568f94ec4":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"f8be22472b7e429dbd745417545a97ad":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"b9ad0304df3a4e80a3b77c0f67da7fe1":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"9c73c4b5e1124fae87034864c38ddff3":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"ab31969c3a01454caec8b1e2239fc1b4":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_a6dcdea3b6b1424f8be58c287e72f835","IPY_MODEL_4c41f17942094a9d9605a76c8cc98e71","IPY_MODEL_ebb788b4002145a99407ae3ef74aa72c"],"layout":"IPY_MODEL_39edb26205bf4fa29a9fb031d7e9033b"}},"a6dcdea3b6b1424f8be58c287e72f835":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_3ff005d78fc94262a2278ef77d444ed6","placeholder":"​","style":"IPY_MODEL_eeb6b759967d4566876ec2e13c7deaa1","value":"Loading checkpoint shards: 100%"}},"4c41f17942094a9d9605a76c8cc98e71":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_d34036ca2b574762a2f084c1d00e3773","max":2,"min":0,"orientation":"horizontal","style":"IPY_MODEL_0a8b26bcde964de9837a9502110ba725","value":2}},"ebb788b4002145a99407ae3ef74aa72c":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_f006930afe4e46b8b8e9df87f296928e","placeholder":"​","style":"IPY_MODEL_ae2e01665211437188c8bc99d98c4ef6","value":" 2/2 [00:56&lt;00:00, 25.53s/it]"}},"39edb26205bf4fa29a9fb031d7e9033b":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"3ff005d78fc94262a2278ef77d444ed6":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"eeb6b759967d4566876ec2e13c7deaa1":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"d34036ca2b574762a2f084c1d00e3773":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"0a8b26bcde964de9837a9502110ba725":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"f006930afe4e46b8b8e9df87f296928e":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"ae2e01665211437188c8bc99d98c4ef6":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}}}},"accelerator":"GPU"},"cells":[{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Na0fGBN9fMd2","executionInfo":{"status":"ok","timestamp":1717798236255,"user_tz":300,"elapsed":11,"user":{"displayName":"Koushik M","userId":"16400000590471005233"}},"outputId":"9d48c328-0226-4d8c-b7db-e3533d2df61a"},"outputs":[{"output_type":"stream","name":"stdout","text":["Fri Jun  7 22:10:35 2024       \n","+---------------------------------------------------------------------------------------+\n","| NVIDIA-SMI 535.104.05             Driver Version: 535.104.05   CUDA Version: 12.2     |\n","|-----------------------------------------+----------------------+----------------------+\n","| GPU  Name                 Persistence-M | Bus-Id        Disp.A | Volatile Uncorr. ECC |\n","| Fan  Temp   Perf          Pwr:Usage/Cap |         Memory-Usage | GPU-Util  Compute M. |\n","|                                         |                      |               MIG M. |\n","|=========================================+======================+======================|\n","|   0  Tesla T4                       Off | 00000000:00:04.0 Off |                    0 |\n","| N/A   34C    P8               9W /  70W |      0MiB / 15360MiB |      0%      Default |\n","|                                         |                      |                  N/A |\n","+-----------------------------------------+----------------------+----------------------+\n","                                                                                         \n","+---------------------------------------------------------------------------------------+\n","| Processes:                                                                            |\n","|  GPU   GI   CI        PID   Type   Process name                            GPU Memory |\n","|        ID   ID                                                             Usage      |\n","|=======================================================================================|\n","|  No running processes found                                                           |\n","+---------------------------------------------------------------------------------------+\n"]}],"source":["!nvidia-smi"]},{"cell_type":"code","source":["\n","!pip install -q pandas\n"],"metadata":{"id":"tu8PBhvnfM3G","executionInfo":{"status":"ok","timestamp":1717798255943,"user_tz":300,"elapsed":15526,"user":{"displayName":"Koushik M","userId":"16400000590471005233"}}},"execution_count":2,"outputs":[]},{"cell_type":"markdown","source":[],"metadata":{"id":"Zr8SNLgbMdca"}},{"cell_type":"code","source":["!pip install -q autotrain-advanced\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"b7lHDwB3fUS2","executionInfo":{"status":"ok","timestamp":1717798471988,"user_tz":300,"elapsed":155353,"user":{"displayName":"Koushik M","userId":"16400000590471005233"}},"outputId":"e385069a-749e-49ec-b64a-c6829fd3430b"},"execution_count":3,"outputs":[{"output_type":"stream","name":"stdout","text":["\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m316.4/316.4 kB\u001b[0m \u001b[31m6.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m155.7/155.7 kB\u001b[0m \u001b[31m9.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m174.6/174.6 kB\u001b[0m \u001b[31m10.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m542.1/542.1 kB\u001b[0m \u001b[31m14.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m84.1/84.1 kB\u001b[0m \u001b[31m11.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.4/13.4 MB\u001b[0m \u001b[31m57.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m301.2/301.2 kB\u001b[0m \u001b[31m34.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.5/62.5 kB\u001b[0m \u001b[31m8.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.0/13.0 MB\u001b[0m \u001b[31m96.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m380.1/380.1 kB\u001b[0m \u001b[31m37.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.5/4.5 MB\u001b[0m \u001b[31m106.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m304.5/304.5 kB\u001b[0m \u001b[31m1.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m897.5/897.5 kB\u001b[0m \u001b[31m71.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.3/13.3 MB\u001b[0m \u001b[31m90.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m72.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m226.8/226.8 kB\u001b[0m \u001b[31m29.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m401.3/401.3 kB\u001b[0m \u001b[31m44.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m44.6/44.6 kB\u001b[0m \u001b[31m5.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m64.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.6/4.6 MB\u001b[0m \u001b[31m83.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m215.4/215.4 kB\u001b[0m \u001b[31m21.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.5/5.5 MB\u001b[0m \u001b[31m81.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m251.6/251.6 kB\u001b[0m \u001b[31m22.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m245.2/245.2 kB\u001b[0m \u001b[31m21.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.8/1.8 MB\u001b[0m \u001b[31m61.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m9.1/9.1 MB\u001b[0m \u001b[31m30.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m302.6/302.6 kB\u001b[0m \u001b[31m26.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.0/2.0 MB\u001b[0m \u001b[31m86.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m67.6/67.6 kB\u001b[0m \u001b[31m9.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m92.0/92.0 kB\u001b[0m \u001b[31m13.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m60.8/60.8 kB\u001b[0m \u001b[31m8.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m409.3/409.3 kB\u001b[0m \u001b[31m38.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.4/4.4 MB\u001b[0m \u001b[31m102.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m223.7/223.7 kB\u001b[0m \u001b[31m24.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m43.6/43.6 kB\u001b[0m \u001b[31m6.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m75.6/75.6 kB\u001b[0m \u001b[31m10.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.3/2.3 MB\u001b[0m \u001b[31m77.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m868.8/868.8 kB\u001b[0m \u001b[31m53.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m224.7/224.7 kB\u001b[0m \u001b[31m18.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m119.8/119.8 MB\u001b[0m \u001b[31m9.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m14.7/14.7 MB\u001b[0m \u001b[31m101.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m66.4/66.4 kB\u001b[0m \u001b[31m9.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m53.1/53.1 kB\u001b[0m \u001b[31m7.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.4/3.4 MB\u001b[0m \u001b[31m79.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m116.3/116.3 kB\u001b[0m \u001b[31m14.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m194.1/194.1 kB\u001b[0m \u001b[31m25.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m134.8/134.8 kB\u001b[0m \u001b[31m19.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m71.9/71.9 kB\u001b[0m \u001b[31m10.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m53.6/53.6 kB\u001b[0m \u001b[31m7.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m142.5/142.5 kB\u001b[0m \u001b[31m18.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.4/62.4 kB\u001b[0m \u001b[31m7.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m77.9/77.9 kB\u001b[0m \u001b[31m10.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m233.4/233.4 kB\u001b[0m \u001b[31m30.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.1/2.1 MB\u001b[0m \u001b[31m92.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m413.8/413.8 kB\u001b[0m \u001b[31m43.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m138.9/138.9 kB\u001b[0m \u001b[31m16.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m49.7/49.7 kB\u001b[0m \u001b[31m7.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m93.1/93.1 kB\u001b[0m \u001b[31m13.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.0/3.0 MB\u001b[0m \u001b[31m99.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.1/2.1 MB\u001b[0m \u001b[31m74.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m102.4/102.4 kB\u001b[0m \u001b[31m14.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.3/58.3 kB\u001b[0m \u001b[31m8.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m542.0/542.0 kB\u001b[0m \u001b[31m50.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m78.6/78.6 kB\u001b[0m \u001b[31m11.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m307.7/307.7 kB\u001b[0m \u001b[31m35.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m47.2/47.2 kB\u001b[0m \u001b[31m6.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m313.5/313.5 kB\u001b[0m \u001b[31m36.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.3/21.3 MB\u001b[0m \u001b[31m73.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.4/62.4 kB\u001b[0m \u001b[31m8.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m341.4/341.4 kB\u001b[0m \u001b[31m38.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.4/3.4 MB\u001b[0m \u001b[31m107.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m81.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m130.2/130.2 kB\u001b[0m \u001b[31m17.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h  Building wheel for ipadic (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Building wheel for rouge-score (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Building wheel for seqeval (setup.py) ... \u001b[?25l\u001b[?25hdone\n","\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n","cudf-cu12 24.4.1 requires pandas<2.2.2dev0,>=2.0, but you have pandas 2.2.2 which is incompatible.\n","google-colab 1.0.0 requires pandas==2.0.3, but you have pandas 2.2.2 which is incompatible.\n","spacy 3.7.4 requires typer<0.10.0,>=0.3.0, but you have typer 0.12.3 which is incompatible.\n","tensorflow 2.15.0 requires tensorboard<2.16,>=2.15, but you have tensorboard 2.16.2 which is incompatible.\n","tensorflow-metadata 1.15.0 requires protobuf<4.21,>=3.20.3; python_version < \"3.11\", but you have protobuf 4.23.4 which is incompatible.\n","weasel 0.3.4 requires typer<0.10.0,>=0.3.0, but you have typer 0.12.3 which is incompatible.\u001b[0m\u001b[31m\n","\u001b[0m"]}]},{"cell_type":"code","source":["!autotrain setup --update-torch\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"LXf6frFHfXEp","executionInfo":{"status":"ok","timestamp":1717798499625,"user_tz":300,"elapsed":24511,"user":{"displayName":"Koushik M","userId":"16400000590471005233"}},"outputId":"3f2fac75-500a-4149-c3ef-66ad4cc41b9d"},"execution_count":4,"outputs":[{"output_type":"stream","name":"stdout","text":["\u001b[1mINFO    \u001b[0m | \u001b[32m2024-06-07 22:14:47\u001b[0m | \u001b[36mautotrain.cli.run_setup\u001b[0m:\u001b[36mrun\u001b[0m:\u001b[36m43\u001b[0m - \u001b[1mInstalling latest xformers\u001b[0m\n","\u001b[1mINFO    \u001b[0m | \u001b[32m2024-06-07 22:14:48\u001b[0m | \u001b[36mautotrain.cli.run_setup\u001b[0m:\u001b[36mrun\u001b[0m:\u001b[36m45\u001b[0m - \u001b[1mSuccessfully installed latest xformers\u001b[0m\n","\u001b[1mINFO    \u001b[0m | \u001b[32m2024-06-07 22:14:48\u001b[0m | \u001b[36mautotrain.cli.run_setup\u001b[0m:\u001b[36mrun\u001b[0m:\u001b[36m51\u001b[0m - \u001b[1mInstalling latest PyTorch\u001b[0m\n","\u001b[1mINFO    \u001b[0m | \u001b[32m2024-06-07 22:14:57\u001b[0m | \u001b[36mautotrain.cli.run_setup\u001b[0m:\u001b[36mrun\u001b[0m:\u001b[36m53\u001b[0m - \u001b[1mSuccessfully installed latest PyTorch\u001b[0m\n"]}]},{"cell_type":"code","source":["from huggingface_hub import notebook_login\n","notebook_login()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":145,"referenced_widgets":["e538b298684d42118237b7d42847800a","2ff9b790c63043e99dccd1a0be98278f","61f083dd5eda4c41bea992900f27b750","1fd9ca95b8bb4a088bd9e2989ae06db3","ccf72b0e4a6543bbabc898eb99fc2d2b","606c311aaba24352b609e58c6a5af634","1bd2bd6c2dd24f9dbaee14ed15c67f4d","d72bc7c145e54e15898de403a760d5c4","06289b2fdc834a2fb91f1c82c9289c59","6f10e2e2e453485e9cb6f00adcc275d6","025c641c62d3402896f704a549fb75c6","1a036fb7a56b49a0b5e123ab7852d2a7","5aa0e23fb9e04e69bd5bac8779ffa13a","e338f306e7d2410f8bfac27858b694d4","fa1178e6fd0242edbf4ff6fcfb661f3f","e7a3df4ae5c84181874080f3772ddb88","58d9fc7476ab4d328fb455b2d9edccac","a4d20611f8404ce78d68e6d35900f088","f4d94a91813f412b9c25f0c8aa2636df","26826a106cc342f897a1f74c67e51a50","fa7f2ccd1c2c4e15a7a3735e1e2a8b78","313eb32858304222b82620a8ad43de26","e66adf54917d4af8a1daea451b2cb286","ebe04aa0f5f94e3e8133533e1b976d01","52470aaa1caf4c8a8b6cfbb4e19a0d30","6eddb37a7769466d9259d0730b112740","d6089d0077634d0e8b39d0adc220bfbb","4d8789a7d65a4a7bb7624f6c076df23f","252a6e2c165d4847be467a4568f94ec4","f8be22472b7e429dbd745417545a97ad","b9ad0304df3a4e80a3b77c0f67da7fe1","9c73c4b5e1124fae87034864c38ddff3"]},"id":"3wzriqiEgOyw","executionInfo":{"status":"ok","timestamp":1717798502758,"user_tz":300,"elapsed":17,"user":{"displayName":"Koushik M","userId":"16400000590471005233"}},"outputId":"cd11a495-45bd-477e-e03e-75365de585c2"},"execution_count":5,"outputs":[{"output_type":"display_data","data":{"text/plain":["VBox(children=(HTML(value='<center> <img\\nsrc=https://huggingface.co/front/assets/huggingface_logo-noborder.sv…"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"e538b298684d42118237b7d42847800a"}},"metadata":{}}]},{"cell_type":"code","source":["!git clone https://github.com/joshbickett/finetune-llama-2.git\n","%cd finetune-llama-2\n","%mv train.csv ../train.csv\n","%cd .."],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"rwqCQqb1gcD7","executionInfo":{"status":"ok","timestamp":1717798518384,"user_tz":300,"elapsed":682,"user":{"displayName":"Koushik M","userId":"16400000590471005233"}},"outputId":"054a50f3-3512-4331-b843-3f2fcabfdb39"},"execution_count":6,"outputs":[{"output_type":"stream","name":"stdout","text":["Cloning into 'finetune-llama-2'...\n","remote: Enumerating objects: 70, done.\u001b[K\n","remote: Counting objects: 100% (70/70), done.\u001b[K\n","remote: Compressing objects: 100% (50/50), done.\u001b[K\n","remote: Total 70 (delta 38), reused 48 (delta 19), pack-reused 0\u001b[K\n","Receiving objects: 100% (70/70), 25.13 KiB | 8.38 MiB/s, done.\n","Resolving deltas: 100% (38/38), done.\n","/content/finetune-llama-2\n","/content\n"]}]},{"cell_type":"code","source":["import pandas as pd\n","df = pd.read_csv(\"train.csv\")\n","df"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":423},"id":"8MlfeDcpgoQK","executionInfo":{"status":"ok","timestamp":1717798526525,"user_tz":300,"elapsed":559,"user":{"displayName":"Koushik M","userId":"16400000590471005233"}},"outputId":"99ec3808-ea6e-45ce-9eb7-3ad12082d651"},"execution_count":7,"outputs":[{"output_type":"execute_result","data":{"text/plain":["                                    Concept  \\\n","0                 A cactus at a dance party   \n","1                   A robot on a first date   \n","2                A snail at a speed contest   \n","3                A penguin at a beach party   \n","4                     A cloud in a bad mood   \n","..                                      ...   \n","112      A donut feeling the hole emptiness   \n","113     A pineapple with a prickly attitude   \n","114  A calculator crunching life's problems   \n","115             A kite reaching new heights   \n","116            A teddy bear feeling stuffed   \n","\n","                              Funny Description Prompt  \\\n","0    A cactus, wearing disco lights and surrounded ...   \n","1    A robot, with a bouquet of USB cables, nervous...   \n","2    A snail, with a mini rocket booster, confident...   \n","3    A penguin, with sunscreen and a surfboard, try...   \n","4    A cloud, grumbling and dropping mini lightning...   \n","..                                                 ...   \n","112  A donut, in existential bakery therapy, ponder...   \n","113  A pineapple, in a prickly personality class, s...   \n","114  A calculator, at a problem-solving workshop, c...   \n","115  A kite, in an altitude adjustment session, unt...   \n","116  A teddy bear, in a fluff mindfulness group, em...   \n","\n","                                                  text  \n","0    ###Human:\\nGenerate a midjourney prompt for A ...  \n","1    ###Human:\\nGenerate a midjourney prompt for A ...  \n","2    ###Human:\\nGenerate a midjourney prompt for A ...  \n","3    ###Human:\\nGenerate a midjourney prompt for A ...  \n","4    ###Human:\\nGenerate a midjourney prompt for A ...  \n","..                                                 ...  \n","112  ###Human:\\nGenerate a midjourney prompt for A ...  \n","113  ###Human:\\nGenerate a midjourney prompt for A ...  \n","114  ###Human:\\nGenerate a midjourney prompt for A ...  \n","115  ###Human:\\nGenerate a midjourney prompt for A ...  \n","116  ###Human:\\nGenerate a midjourney prompt for A ...  \n","\n","[117 rows x 3 columns]"],"text/html":["\n","  <div id=\"df-4c739c12-fa9a-481b-807b-c5f2176ace41\" class=\"colab-df-container\">\n","    <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Concept</th>\n","      <th>Funny Description Prompt</th>\n","      <th>text</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>A cactus at a dance party</td>\n","      <td>A cactus, wearing disco lights and surrounded ...</td>\n","      <td>###Human:\\nGenerate a midjourney prompt for A ...</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>A robot on a first date</td>\n","      <td>A robot, with a bouquet of USB cables, nervous...</td>\n","      <td>###Human:\\nGenerate a midjourney prompt for A ...</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>A snail at a speed contest</td>\n","      <td>A snail, with a mini rocket booster, confident...</td>\n","      <td>###Human:\\nGenerate a midjourney prompt for A ...</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>A penguin at a beach party</td>\n","      <td>A penguin, with sunscreen and a surfboard, try...</td>\n","      <td>###Human:\\nGenerate a midjourney prompt for A ...</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>A cloud in a bad mood</td>\n","      <td>A cloud, grumbling and dropping mini lightning...</td>\n","      <td>###Human:\\nGenerate a midjourney prompt for A ...</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>112</th>\n","      <td>A donut feeling the hole emptiness</td>\n","      <td>A donut, in existential bakery therapy, ponder...</td>\n","      <td>###Human:\\nGenerate a midjourney prompt for A ...</td>\n","    </tr>\n","    <tr>\n","      <th>113</th>\n","      <td>A pineapple with a prickly attitude</td>\n","      <td>A pineapple, in a prickly personality class, s...</td>\n","      <td>###Human:\\nGenerate a midjourney prompt for A ...</td>\n","    </tr>\n","    <tr>\n","      <th>114</th>\n","      <td>A calculator crunching life's problems</td>\n","      <td>A calculator, at a problem-solving workshop, c...</td>\n","      <td>###Human:\\nGenerate a midjourney prompt for A ...</td>\n","    </tr>\n","    <tr>\n","      <th>115</th>\n","      <td>A kite reaching new heights</td>\n","      <td>A kite, in an altitude adjustment session, unt...</td>\n","      <td>###Human:\\nGenerate a midjourney prompt for A ...</td>\n","    </tr>\n","    <tr>\n","      <th>116</th>\n","      <td>A teddy bear feeling stuffed</td>\n","      <td>A teddy bear, in a fluff mindfulness group, em...</td>\n","      <td>###Human:\\nGenerate a midjourney prompt for A ...</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>117 rows × 3 columns</p>\n","</div>\n","    <div class=\"colab-df-buttons\">\n","\n","  <div class=\"colab-df-container\">\n","    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-4c739c12-fa9a-481b-807b-c5f2176ace41')\"\n","            title=\"Convert this dataframe to an interactive table.\"\n","            style=\"display:none;\">\n","\n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n","    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n","  </svg>\n","    </button>\n","\n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    .colab-df-buttons div {\n","      margin-bottom: 4px;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","    <script>\n","      const buttonEl =\n","        document.querySelector('#df-4c739c12-fa9a-481b-807b-c5f2176ace41 button.colab-df-convert');\n","      buttonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","      async function convertToInteractive(key) {\n","        const element = document.querySelector('#df-4c739c12-fa9a-481b-807b-c5f2176ace41');\n","        const dataTable =\n","          await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                    [key], {});\n","        if (!dataTable) return;\n","\n","        const docLinkHtml = 'Like what you see? Visit the ' +\n","          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","          + ' to learn more about interactive tables.';\n","        element.innerHTML = '';\n","        dataTable['output_type'] = 'display_data';\n","        await google.colab.output.renderOutput(dataTable, element);\n","        const docLink = document.createElement('div');\n","        docLink.innerHTML = docLinkHtml;\n","        element.appendChild(docLink);\n","      }\n","    </script>\n","  </div>\n","\n","\n","<div id=\"df-d34469c6-7aca-4d3b-b078-22a68423da37\">\n","  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-d34469c6-7aca-4d3b-b078-22a68423da37')\"\n","            title=\"Suggest charts\"\n","            style=\"display:none;\">\n","\n","<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","     width=\"24px\">\n","    <g>\n","        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n","    </g>\n","</svg>\n","  </button>\n","\n","<style>\n","  .colab-df-quickchart {\n","      --bg-color: #E8F0FE;\n","      --fill-color: #1967D2;\n","      --hover-bg-color: #E2EBFA;\n","      --hover-fill-color: #174EA6;\n","      --disabled-fill-color: #AAA;\n","      --disabled-bg-color: #DDD;\n","  }\n","\n","  [theme=dark] .colab-df-quickchart {\n","      --bg-color: #3B4455;\n","      --fill-color: #D2E3FC;\n","      --hover-bg-color: #434B5C;\n","      --hover-fill-color: #FFFFFF;\n","      --disabled-bg-color: #3B4455;\n","      --disabled-fill-color: #666;\n","  }\n","\n","  .colab-df-quickchart {\n","    background-color: var(--bg-color);\n","    border: none;\n","    border-radius: 50%;\n","    cursor: pointer;\n","    display: none;\n","    fill: var(--fill-color);\n","    height: 32px;\n","    padding: 0;\n","    width: 32px;\n","  }\n","\n","  .colab-df-quickchart:hover {\n","    background-color: var(--hover-bg-color);\n","    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n","    fill: var(--button-hover-fill-color);\n","  }\n","\n","  .colab-df-quickchart-complete:disabled,\n","  .colab-df-quickchart-complete:disabled:hover {\n","    background-color: var(--disabled-bg-color);\n","    fill: var(--disabled-fill-color);\n","    box-shadow: none;\n","  }\n","\n","  .colab-df-spinner {\n","    border: 2px solid var(--fill-color);\n","    border-color: transparent;\n","    border-bottom-color: var(--fill-color);\n","    animation:\n","      spin 1s steps(1) infinite;\n","  }\n","\n","  @keyframes spin {\n","    0% {\n","      border-color: transparent;\n","      border-bottom-color: var(--fill-color);\n","      border-left-color: var(--fill-color);\n","    }\n","    20% {\n","      border-color: transparent;\n","      border-left-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","    }\n","    30% {\n","      border-color: transparent;\n","      border-left-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","      border-right-color: var(--fill-color);\n","    }\n","    40% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","    }\n","    60% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","    }\n","    80% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","      border-bottom-color: var(--fill-color);\n","    }\n","    90% {\n","      border-color: transparent;\n","      border-bottom-color: var(--fill-color);\n","    }\n","  }\n","</style>\n","\n","  <script>\n","    async function quickchart(key) {\n","      const quickchartButtonEl =\n","        document.querySelector('#' + key + ' button');\n","      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n","      quickchartButtonEl.classList.add('colab-df-spinner');\n","      try {\n","        const charts = await google.colab.kernel.invokeFunction(\n","            'suggestCharts', [key], {});\n","      } catch (error) {\n","        console.error('Error during call to suggestCharts:', error);\n","      }\n","      quickchartButtonEl.classList.remove('colab-df-spinner');\n","      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n","    }\n","    (() => {\n","      let quickchartButtonEl =\n","        document.querySelector('#df-d34469c6-7aca-4d3b-b078-22a68423da37 button');\n","      quickchartButtonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","    })();\n","  </script>\n","</div>\n","\n","  <div id=\"id_3faead24-eb78-41b6-aecf-1eade612181b\">\n","    <style>\n","      .colab-df-generate {\n","        background-color: #E8F0FE;\n","        border: none;\n","        border-radius: 50%;\n","        cursor: pointer;\n","        display: none;\n","        fill: #1967D2;\n","        height: 32px;\n","        padding: 0 0 0 0;\n","        width: 32px;\n","      }\n","\n","      .colab-df-generate:hover {\n","        background-color: #E2EBFA;\n","        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","        fill: #174EA6;\n","      }\n","\n","      [theme=dark] .colab-df-generate {\n","        background-color: #3B4455;\n","        fill: #D2E3FC;\n","      }\n","\n","      [theme=dark] .colab-df-generate:hover {\n","        background-color: #434B5C;\n","        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","        fill: #FFFFFF;\n","      }\n","    </style>\n","    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('df')\"\n","            title=\"Generate code using this dataframe.\"\n","            style=\"display:none;\">\n","\n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n","  </svg>\n","    </button>\n","    <script>\n","      (() => {\n","      const buttonEl =\n","        document.querySelector('#id_3faead24-eb78-41b6-aecf-1eade612181b button.colab-df-generate');\n","      buttonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","      buttonEl.onclick = () => {\n","        google.colab.notebook.generateWithVariable('df');\n","      }\n","      })();\n","    </script>\n","  </div>\n","\n","    </div>\n","  </div>\n"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"dataframe","variable_name":"df","summary":"{\n  \"name\": \"df\",\n  \"rows\": 117,\n  \"fields\": [\n    {\n      \"column\": \"Concept\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 109,\n        \"samples\": [\n          \"A candle with a burning question\",\n          \"A star wishing upon humans\",\n          \"A cloud in a bad mood\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Funny Description Prompt\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 112,\n        \"samples\": [\n          \"A watch, in a time management seminar, figuring out how to make the most of its ticking moments.\",\n          \"A scarecrow, in a sharp suit, leading a meeting with crows, setting productivity targets for the field.\",\n          \"A cloud, grumbling and dropping mini lightning bolts, attending an anger management session with other weather elements.\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"text\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 112,\n        \"samples\": [\n          \"###Human:\\nGenerate a midjourney prompt for A watch that's out of its time\\n\\n###Assistant:\\nA watch, in a time management seminar, figuring out how to make the most of its ticking moments.\",\n          \"###Human:\\nGenerate a midjourney prompt for A scarecrow promoted to manager\\n\\n###Assistant:\\nA scarecrow, in a sharp suit, leading a meeting with crows, setting productivity targets for the field.\",\n          \"###Human:\\nGenerate a midjourney prompt for A cloud in a bad mood\\n\\n###Assistant:\\nA cloud, grumbling and dropping mini lightning bolts, attending an anger management session with other weather elements.\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"}},"metadata":{},"execution_count":7}]},{"cell_type":"code","source":["df['text'][13]"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":35},"id":"CDvC5qgbgqpH","executionInfo":{"status":"ok","timestamp":1717798531368,"user_tz":300,"elapsed":406,"user":{"displayName":"Koushik M","userId":"16400000590471005233"}},"outputId":"1d43ce71-beb6-4860-8358-babc0c033dbf"},"execution_count":8,"outputs":[{"output_type":"execute_result","data":{"text/plain":["'###Human:\\nGenerate a midjourney prompt for A penguin at a beach party\\n\\n###Assistant:\\nA penguin, with sunscreen and a surfboard, trying to mingle with the seagulls, while sipping a cold ice drink.'"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"}},"metadata":{},"execution_count":8}]},{"cell_type":"code","source":["!autotrain llm --train \\\n","    --project-name Mistral-Finetuned \\\n","    --model mistralai/Mistral-7B-Instruct-v0.1\\\n","    --data-path . \\\n","    --peft \\\n","    --quantization int4 \\\n","    --lr 2e-4 \\\n","    --batch-size 12 \\\n","    --epochs 3 \\\n","    --trainer sft \\\n","    --target-modules q_proj,v_proj \\\n","    --push-to-hub \\\n","    --username koushik9121 \\\n","    --token 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\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"NGoPLIhAguAQ","executionInfo":{"status":"ok","timestamp":1717799842163,"user_tz":300,"elapsed":298006,"user":{"displayName":"Koushik M","userId":"16400000590471005233"}},"outputId":"7ed7baa4-7327-47ae-bfc6-c75d6bd609cc"},"execution_count":24,"outputs":[{"output_type":"stream","name":"stdout","text":["\u001b[1mINFO    \u001b[0m | \u001b[32m2024-06-07 22:32:29\u001b[0m | \u001b[36mautotrain.cli.run_llm\u001b[0m:\u001b[36mrun\u001b[0m:\u001b[36m344\u001b[0m - \u001b[1mRunning LLM\u001b[0m\n","\u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[32m2024-06-07 22:32:29\u001b[0m | \u001b[36mautotrain.trainers.common\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m180\u001b[0m - \u001b[33m\u001b[1mParameters supplied but not used: backend, func, inference, deploy, train, version, config\u001b[0m\n","\rSaving the dataset (0/1 shards):   0% 0/117 [00:00<?, ? examples/s]\rSaving the dataset (1/1 shards): 100% 117/117 [00:00<00:00, 44660.86 examples/s]\rSaving the dataset (1/1 shards): 100% 117/117 [00:00<00:00, 41485.63 examples/s]\n","\rSaving the dataset (0/1 shards):   0% 0/117 [00:00<?, ? examples/s]\rSaving the dataset (1/1 shards): 100% 117/117 [00:00<00:00, 48172.53 examples/s]\rSaving the dataset (1/1 shards): 100% 117/117 [00:00<00:00, 45854.38 examples/s]\n","\u001b[1mINFO    \u001b[0m | \u001b[32m2024-06-07 22:32:29\u001b[0m | \u001b[36mautotrain.backends.local\u001b[0m:\u001b[36mcreate\u001b[0m:\u001b[36m8\u001b[0m - \u001b[1mStarting local training...\u001b[0m\n","\u001b[1mINFO    \u001b[0m | \u001b[32m2024-06-07 22:32:29\u001b[0m | \u001b[36mautotrain.commands\u001b[0m:\u001b[36mlaunch_command\u001b[0m:\u001b[36m386\u001b[0m - \u001b[1m['accelerate', 'launch', '--num_machines', '1', '--num_processes', '1', '--mixed_precision', 'no', '-m', 'autotrain.trainers.clm', '--training_config', 'Mistral-Finetuned/training_params.json']\u001b[0m\n","\u001b[1mINFO    \u001b[0m | \u001b[32m2024-06-07 22:32:29\u001b[0m | \u001b[36mautotrain.commands\u001b[0m:\u001b[36mlaunch_command\u001b[0m:\u001b[36m387\u001b[0m - \u001b[1m{'model': 'mistralai/Mistral-7B-Instruct-v0.1', 'project_name': 'Mistral-Finetuned', 'data_path': 'Mistral-Finetuned/autotrain-data', 'train_split': 'train', 'valid_split': None, 'add_eos_token': False, 'block_size': -1, 'model_max_length': 1024, 'padding': None, 'trainer': 'sft', 'use_flash_attention_2': False, 'log': 'none', 'disable_gradient_checkpointing': False, 'logging_steps': -1, 'evaluation_strategy': 'epoch', 'save_total_limit': 1, 'auto_find_batch_size': False, 'mixed_precision': None, 'lr': 0.0002, 'epochs': 3, 'batch_size': 12, 'warmup_ratio': 0.1, 'gradient_accumulation': 1, 'optimizer': 'adamw_torch', 'scheduler': 'linear', 'weight_decay': 0.0, 'max_grad_norm': 1.0, 'seed': 42, 'chat_template': None, 'quantization': 'int4', 'target_modules': 'q_proj,v_proj', 'merge_adapter': False, 'peft': True, 'lora_r': 16, 'lora_alpha': 32, 'lora_dropout': 0.05, 'model_ref': None, 'dpo_beta': 0.1, 'max_prompt_length': 128, 'max_completion_length': None, 'prompt_text_column': 'autotrain_prompt', 'text_column': 'autotrain_text', 'rejected_text_column': 'autotrain_rejected_text', 'push_to_hub': True, 'username': 'koushik9121', 'token': '*****'}\u001b[0m\n","The following values were not passed to `accelerate launch` and had defaults used instead:\n","\t`--dynamo_backend` was set to a value of `'no'`\n","To avoid this warning pass in values for each of the problematic parameters or run `accelerate config`.\n","\u001b[1mINFO    \u001b[0m | \u001b[32m2024-06-07 22:32:40\u001b[0m | \u001b[36mautotrain.trainers.clm.train_clm_sft\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m14\u001b[0m - \u001b[1mStarting SFT training...\u001b[0m\n","\u001b[1mINFO    \u001b[0m | \u001b[32m2024-06-07 22:32:40\u001b[0m | \u001b[36mautotrain.trainers.clm.utils\u001b[0m:\u001b[36mprocess_input_data\u001b[0m:\u001b[36m335\u001b[0m - \u001b[1mloading dataset from disk\u001b[0m\n","\u001b[1mINFO    \u001b[0m | \u001b[32m2024-06-07 22:32:40\u001b[0m | \u001b[36mautotrain.trainers.clm.utils\u001b[0m:\u001b[36mprocess_input_data\u001b[0m:\u001b[36m394\u001b[0m - \u001b[1mTrain data: Dataset({\n","    features: ['Concept', 'Funny Description Prompt', 'autotrain_text'],\n","    num_rows: 117\n","})\u001b[0m\n","\u001b[1mINFO    \u001b[0m | \u001b[32m2024-06-07 22:32:40\u001b[0m | \u001b[36mautotrain.trainers.clm.utils\u001b[0m:\u001b[36mprocess_input_data\u001b[0m:\u001b[36m395\u001b[0m - \u001b[1mValid data: None\u001b[0m\n","\u001b[1mINFO    \u001b[0m | \u001b[32m2024-06-07 22:32:40\u001b[0m | \u001b[36mautotrain.trainers.clm.utils\u001b[0m:\u001b[36mconfigure_logging_steps\u001b[0m:\u001b[36m467\u001b[0m - \u001b[1mconfiguring logging steps\u001b[0m\n","\u001b[1mINFO    \u001b[0m | \u001b[32m2024-06-07 22:32:40\u001b[0m | \u001b[36mautotrain.trainers.clm.utils\u001b[0m:\u001b[36mconfigure_logging_steps\u001b[0m:\u001b[36m480\u001b[0m - \u001b[1mLogging steps: 1\u001b[0m\n","\u001b[1mINFO    \u001b[0m | \u001b[32m2024-06-07 22:32:40\u001b[0m | \u001b[36mautotrain.trainers.clm.utils\u001b[0m:\u001b[36mconfigure_training_args\u001b[0m:\u001b[36m485\u001b[0m - \u001b[1mconfiguring training args\u001b[0m\n","\u001b[1mINFO    \u001b[0m | \u001b[32m2024-06-07 22:32:40\u001b[0m | \u001b[36mautotrain.trainers.clm.utils\u001b[0m:\u001b[36mconfigure_block_size\u001b[0m:\u001b[36m548\u001b[0m - \u001b[1mUsing block size 1024\u001b[0m\n","/usr/local/lib/python3.10/dist-packages/transformers/training_args.py:1474: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of 🤗 Transformers. Use `eval_strategy` instead\n","  warnings.warn(\n","\u001b[1mINFO    \u001b[0m | \u001b[32m2024-06-07 22:32:40\u001b[0m | \u001b[36mautotrain.trainers.clm.train_clm_sft\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m27\u001b[0m - \u001b[1mloading model config...\u001b[0m\n","/usr/local/lib/python3.10/dist-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n","  warnings.warn(\n","\u001b[1mINFO    \u001b[0m | \u001b[32m2024-06-07 22:32:40\u001b[0m | \u001b[36mautotrain.trainers.clm.train_clm_sft\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m35\u001b[0m - \u001b[1mloading model...\u001b[0m\n","`low_cpu_mem_usage` was None, now set to True since model is quantized.\n","Downloading shards:   0% 0/2 [00:00<?, ?it/s]\n","model-00002-of-00002.safetensors:  18% 839M/4.54G [00:00<?, ?B/s]\u001b[A\n","model-00002-of-00002.safetensors:  19% 870M/4.54G [00:00<00:14, 252MB/s]\u001b[A\n","model-00002-of-00002.safetensors:  20% 923M/4.54G [00:00<00:09, 364MB/s]\u001b[A\n","model-00002-of-00002.safetensors:  21% 965M/4.54G [00:00<00:09, 365MB/s]\u001b[A\n","model-00002-of-00002.safetensors:  22% 1.01G/4.54G [00:00<00:10, 339MB/s]\u001b[A\n","model-00002-of-00002.safetensors:  23% 1.05G/4.54G [00:00<00:11, 309MB/s]\u001b[A\n","model-00002-of-00002.safetensors:  24% 1.09G/4.54G [00:00<00:11, 308MB/s]\u001b[A\n","model-00002-of-00002.safetensors:  25% 1.13G/4.54G [00:00<00:10, 315MB/s]\u001b[A\n","model-00002-of-00002.safetensors:  26% 1.17G/4.54G [00:01<00:11, 305MB/s]\u001b[A\n","model-00002-of-00002.safetensors:  27% 1.22G/4.54G [00:01<00:10, 312MB/s]\u001b[A\n","model-00002-of-00002.safetensors:  28% 1.26G/4.54G [00:01<00:10, 313MB/s]\u001b[A\n","model-00002-of-00002.safetensors:  29% 1.30G/4.54G [00:01<00:10, 320MB/s]\u001b[A\n","model-00002-of-00002.safetensors:  30% 1.34G/4.54G [00:01<00:10, 319MB/s]\u001b[A\n","model-00002-of-00002.safetensors:  30% 1.38G/4.54G [00:01<00:10, 300MB/s]\u001b[A\n","model-00002-of-00002.safetensors:  31% 1.42G/4.54G [00:01<00:10, 296MB/s]\u001b[A\n","model-00002-of-00002.safetensors:  32% 1.45G/4.54G [00:01<00:11, 276MB/s]\u001b[A\n","model-00002-of-00002.safetensors:  33% 1.48G/4.54G [00:02<00:11, 275MB/s]\u001b[A\n","model-00002-of-00002.safetensors:  33% 1.51G/4.54G [00:02<00:11, 268MB/s]\u001b[A\n","model-00002-of-00002.safetensors:  34% 1.54G/4.54G [00:04<01:06, 44.9MB/s]\u001b[A\n","model-00002-of-00002.safetensors:  35% 1.58G/4.54G [00:04<00:45, 65.4MB/s]\u001b[A\n","model-00002-of-00002.safetensors:  36% 1.64G/4.54G [00:04<00:29, 97.0MB/s]\u001b[A\n","model-00002-of-00002.safetensors:  37% 1.67G/4.54G [00:04<00:25, 114MB/s] \u001b[A\n","model-00002-of-00002.safetensors:  37% 1.70G/4.54G [00:04<00:21, 135MB/s]\u001b[A\n","model-00002-of-00002.safetensors:  38% 1.74G/4.54G [00:04<00:16, 166MB/s]\u001b[A\n","model-00002-of-00002.safetensors:  39% 1.77G/4.54G [00:05<00:14, 187MB/s]\u001b[A\n","model-00002-of-00002.safetensors:  40% 1.81G/4.54G [00:05<00:12, 217MB/s]\u001b[A\n","model-00002-of-00002.safetensors:  41% 1.86G/4.54G [00:05<00:11, 242MB/s]\u001b[A\n","model-00002-of-00002.safetensors:  42% 1.90G/4.54G [00:05<00:10, 262MB/s]\u001b[A\n","model-00002-of-00002.safetensors:  43% 1.94G/4.54G [00:05<00:09, 285MB/s]\u001b[A\n","model-00002-of-00002.safetensors:  44% 1.98G/4.54G [00:05<00:08, 301MB/s]\u001b[A\n","model-00002-of-00002.safetensors:  45% 2.02G/4.54G [00:05<00:08, 306MB/s]\u001b[A\n","model-00002-of-00002.safetensors:  45% 2.07G/4.54G [00:06<00:08, 291MB/s]\u001b[A\n","model-00002-of-00002.safetensors:  46% 2.10G/4.54G [00:06<00:08, 287MB/s]\u001b[A\n","model-00002-of-00002.safetensors:  47% 2.13G/4.54G [00:06<00:08, 278MB/s]\u001b[A\n","model-00002-of-00002.safetensors:  48% 2.16G/4.54G [00:06<00:08, 268MB/s]\u001b[A\n","model-00002-of-00002.safetensors:  48% 2.19G/4.54G [00:08<00:50, 46.5MB/s]\u001b[A\n","model-00002-of-00002.safetensors:  49% 2.24G/4.54G [00:08<00:31, 72.1MB/s]\u001b[A\n","model-00002-of-00002.safetensors:  50% 2.29G/4.54G [00:08<00:23, 96.2MB/s]\u001b[A\n","model-00002-of-00002.safetensors:  51% 2.32G/4.54G [00:08<00:19, 117MB/s] \u001b[A\n","model-00002-of-00002.safetensors:  52% 2.36G/4.54G [00:08<00:14, 146MB/s]\u001b[A\n","model-00002-of-00002.safetensors:  53% 2.39G/4.54G [00:09<00:12, 167MB/s]\u001b[A\n","model-00002-of-00002.safetensors:  53% 2.42G/4.54G [00:09<00:11, 189MB/s]\u001b[A\n","model-00002-of-00002.safetensors:  54% 2.46G/4.54G [00:09<00:09, 222MB/s]\u001b[A\n","model-00002-of-00002.safetensors:  55% 2.51G/4.54G [00:09<00:08, 249MB/s]\u001b[A\n","model-00002-of-00002.safetensors:  56% 2.55G/4.54G [00:09<00:07, 272MB/s]\u001b[A\n","model-00002-of-00002.safetensors:  57% 2.59G/4.54G [00:09<00:06, 286MB/s]\u001b[A\n","model-00002-of-00002.safetensors:  58% 2.63G/4.54G [00:09<00:06, 301MB/s]\u001b[A\n","model-00002-of-00002.safetensors:  59% 2.67G/4.54G [00:10<00:06, 272MB/s]\u001b[A\n","model-00002-of-00002.safetensors:  60% 2.71G/4.54G [00:10<00:06, 271MB/s]\u001b[A\n","model-00002-of-00002.safetensors:  60% 2.74G/4.54G [00:10<00:06, 269MB/s]\u001b[A\n","model-00002-of-00002.safetensors:  61% 2.77G/4.54G [00:10<00:06, 277MB/s]\u001b[A\n","model-00002-of-00002.safetensors:  62% 2.80G/4.54G [00:10<00:06, 258MB/s]\u001b[A\n","model-00002-of-00002.safetensors:  62% 2.83G/4.54G [00:12<00:40, 41.8MB/s]\u001b[A\n","model-00002-of-00002.safetensors:  64% 2.88G/4.54G [00:12<00:25, 65.9MB/s]\u001b[A\n","model-00002-of-00002.safetensors:  64% 2.93G/4.54G [00:13<00:18, 89.2MB/s]\u001b[A\n","model-00002-of-00002.safetensors:  65% 2.97G/4.54G [00:13<00:13, 114MB/s] \u001b[A\n","model-00002-of-00002.safetensors:  66% 3.00G/4.54G [00:13<00:11, 133MB/s]\u001b[A\n","model-00002-of-00002.safetensors:  67% 3.04G/4.54G [00:13<00:09, 164MB/s]\u001b[A\n","model-00002-of-00002.safetensors:  68% 3.08G/4.54G [00:13<00:07, 194MB/s]\u001b[A\n","model-00002-of-00002.safetensors:  69% 3.12G/4.54G [00:13<00:06, 221MB/s]\u001b[A\n","model-00002-of-00002.safetensors:  70% 3.16G/4.54G [00:13<00:05, 234MB/s]\u001b[A\n","model-00002-of-00002.safetensors:  70% 3.20G/4.54G [00:13<00:05, 258MB/s]\u001b[A\n","model-00002-of-00002.safetensors:  71% 3.23G/4.54G [00:14<00:05, 253MB/s]\u001b[A\n","model-00002-of-00002.safetensors:  72% 3.26G/4.54G [00:14<00:05, 232MB/s]\u001b[A\n","model-00002-of-00002.safetensors:  73% 3.29G/4.54G [00:14<00:05, 221MB/s]\u001b[A\n","model-00002-of-00002.safetensors:  73% 3.32G/4.54G [00:14<00:05, 212MB/s]\u001b[A\n","model-00002-of-00002.safetensors:  74% 3.36G/4.54G [00:14<00:05, 208MB/s]\u001b[A\n","model-00002-of-00002.safetensors:  75% 3.39G/4.54G [00:14<00:05, 194MB/s]\u001b[A\n","model-00002-of-00002.safetensors:  75% 3.41G/4.54G [00:15<00:06, 187MB/s]\u001b[A\n","model-00002-of-00002.safetensors:  76% 3.43G/4.54G [00:18<00:50, 21.9MB/s]\u001b[A\n","model-00002-of-00002.safetensors:  76% 3.47G/4.54G [00:18<00:30, 35.5MB/s]\u001b[A\n","model-00002-of-00002.safetensors:  77% 3.50G/4.54G [00:18<00:21, 48.4MB/s]\u001b[A\n","model-00002-of-00002.safetensors:  78% 3.54G/4.54G [00:19<00:14, 69.8MB/s]\u001b[A\n","model-00002-of-00002.safetensors:  79% 3.59G/4.54G [00:19<00:10, 94.9MB/s]\u001b[A\n","model-00002-of-00002.safetensors:  80% 3.63G/4.54G [00:19<00:07, 124MB/s] \u001b[A\n","model-00002-of-00002.safetensors:  81% 3.66G/4.54G [00:19<00:06, 144MB/s]\u001b[A\n","model-00002-of-00002.safetensors:  82% 3.70G/4.54G [00:19<00:04, 177MB/s]\u001b[A\n","model-00002-of-00002.safetensors:  82% 3.73G/4.54G [00:19<00:04, 199MB/s]\u001b[A\n","model-00002-of-00002.safetensors:  83% 3.77G/4.54G [00:19<00:03, 228MB/s]\u001b[A\n","model-00002-of-00002.safetensors:  84% 3.81G/4.54G [00:19<00:03, 243MB/s]\u001b[A\n","model-00002-of-00002.safetensors:  85% 3.85G/4.54G [00:20<00:02, 268MB/s]\u001b[A\n","model-00002-of-00002.safetensors:  86% 3.89G/4.54G [00:20<00:02, 282MB/s]\u001b[A\n","model-00002-of-00002.safetensors:  87% 3.93G/4.54G [00:20<00:02, 298MB/s]\u001b[A\n","model-00002-of-00002.safetensors:  88% 3.97G/4.54G [00:20<00:02, 264MB/s]\u001b[A\n","model-00002-of-00002.safetensors:  88% 4.01G/4.54G [00:20<00:02, 258MB/s]\u001b[A\n","model-00002-of-00002.safetensors:  89% 4.04G/4.54G [00:20<00:01, 253MB/s]\u001b[A\n","model-00002-of-00002.safetensors:  90% 4.07G/4.54G [00:20<00:01, 246MB/s]\u001b[A\n","model-00002-of-00002.safetensors:  91% 4.11G/4.54G [00:21<00:01, 268MB/s]\u001b[A\n","model-00002-of-00002.safetensors:  91% 4.14G/4.54G [00:21<00:03, 126MB/s]\u001b[A\n","model-00002-of-00002.safetensors:  92% 4.16G/4.54G [00:21<00:03, 121MB/s]\u001b[A\n","model-00002-of-00002.safetensors:  92% 4.19G/4.54G [00:21<00:02, 144MB/s]\u001b[A\n","model-00002-of-00002.safetensors:  93% 4.23G/4.54G [00:22<00:01, 161MB/s]\u001b[A\n","model-00002-of-00002.safetensors:  94% 4.26G/4.54G [00:22<00:01, 179MB/s]\u001b[A\n","model-00002-of-00002.safetensors:  94% 4.29G/4.54G [00:22<00:01, 189MB/s]\u001b[A\n","model-00002-of-00002.safetensors:  95% 4.32G/4.54G [00:25<00:06, 33.3MB/s]\u001b[A\n","model-00002-of-00002.safetensors:  96% 4.36G/4.54G [00:25<00:03, 50.1MB/s]\u001b[A\n","model-00002-of-00002.safetensors:  97% 4.40G/4.54G [00:25<00:01, 71.4MB/s]\u001b[A\n","model-00002-of-00002.safetensors:  98% 4.45G/4.54G [00:25<00:00, 95.0MB/s]\u001b[A\n","model-00002-of-00002.safetensors:  99% 4.48G/4.54G [00:25<00:00, 113MB/s] \u001b[A\n","model-00002-of-00002.safetensors:  99% 4.51G/4.54G [00:25<00:00, 132MB/s]\u001b[A\n","model-00002-of-00002.safetensors: 100% 4.54G/4.54G [00:25<00:00, 143MB/s]\n","Downloading shards: 100% 2/2 [00:26<00:00, 13.03s/it]\n","Loading checkpoint shards: 100% 2/2 [01:10<00:00, 35.32s/it]\n","generation_config.json: 100% 116/116 [00:00<00:00, 872kB/s]\n","\u001b[1mINFO    \u001b[0m | \u001b[32m2024-06-07 22:34:22\u001b[0m | \u001b[36mautotrain.trainers.clm.train_clm_sft\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m66\u001b[0m - \u001b[1mmodel dtype: torch.float16\u001b[0m\n","\u001b[1mINFO    \u001b[0m | \u001b[32m2024-06-07 22:34:22\u001b[0m | \u001b[36mautotrain.trainers.clm.train_clm_sft\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m79\u001b[0m - \u001b[1mcreating trainer\u001b[0m\n","/usr/local/lib/python3.10/dist-packages/transformers/training_args.py:1474: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of 🤗 Transformers. Use `eval_strategy` instead\n","  warnings.warn(\n","Generating train split: 5 examples [00:00, 88.03 examples/s]\n","/usr/local/lib/python3.10/dist-packages/trl/trainer/sft_trainer.py:318: UserWarning: You passed a tokenizer with `padding_side` not equal to `right` to the SFTTrainer. This might lead to some unexpected behaviour due to overflow issues when training a model in half-precision. You might consider adding `tokenizer.padding_side = 'right'` to your code.\n","  warnings.warn(\n","\u001b[1mINFO    \u001b[0m | \u001b[32m2024-06-07 22:34:23\u001b[0m | \u001b[36mautotrain.trainers.common\u001b[0m:\u001b[36mon_train_begin\u001b[0m:\u001b[36m231\u001b[0m - \u001b[1mStarting to train...\u001b[0m\n"," 33% 1/3 [00:56<01:52, 56.08s/it]\u001b[1mINFO    \u001b[0m | \u001b[32m2024-06-07 22:35:19\u001b[0m | \u001b[36mautotrain.trainers.common\u001b[0m:\u001b[36mon_log\u001b[0m:\u001b[36m226\u001b[0m - \u001b[1m{'loss': 1.6708, 'grad_norm': 1.6932129859924316, 'learning_rate': 0.0002, 'epoch': 1.0}\u001b[0m\n","{'loss': 1.6708, 'grad_norm': 1.6932129859924316, 'learning_rate': 0.0002, 'epoch': 1.0}\n"," 67% 2/3 [01:52<00:56, 56.29s/it]\u001b[1mINFO    \u001b[0m | \u001b[32m2024-06-07 22:36:16\u001b[0m | \u001b[36mautotrain.trainers.common\u001b[0m:\u001b[36mon_log\u001b[0m:\u001b[36m226\u001b[0m - \u001b[1m{'loss': 1.6708, 'grad_norm': 1.6943186521530151, 'learning_rate': 0.0001, 'epoch': 2.0}\u001b[0m\n","{'loss': 1.6708, 'grad_norm': 1.6943186521530151, 'learning_rate': 0.0001, 'epoch': 2.0}\n","100% 3/3 [02:50<00:00, 57.13s/it]\u001b[1mINFO    \u001b[0m | \u001b[32m2024-06-07 22:37:14\u001b[0m | \u001b[36mautotrain.trainers.common\u001b[0m:\u001b[36mon_log\u001b[0m:\u001b[36m226\u001b[0m - \u001b[1m{'loss': 1.5225, 'grad_norm': 1.602959156036377, 'learning_rate': 0.0, 'epoch': 3.0}\u001b[0m\n","{'loss': 1.5225, 'grad_norm': 1.602959156036377, 'learning_rate': 0.0, 'epoch': 3.0}\n","100% 3/3 [02:50<00:00, 57.13s/it]\u001b[1mINFO    \u001b[0m | \u001b[32m2024-06-07 22:37:14\u001b[0m | \u001b[36mautotrain.trainers.common\u001b[0m:\u001b[36mon_log\u001b[0m:\u001b[36m226\u001b[0m - \u001b[1m{'train_runtime': 170.646, 'train_samples_per_second': 0.088, 'train_steps_per_second': 0.018, 'train_loss': 1.6213488976160686, 'epoch': 3.0}\u001b[0m\n","{'train_runtime': 170.646, 'train_samples_per_second': 0.088, 'train_steps_per_second': 0.018, 'train_loss': 1.6213488976160686, 'epoch': 3.0}\n","100% 3/3 [02:50<00:00, 56.88s/it]\n","\u001b[1mINFO    \u001b[0m | \u001b[32m2024-06-07 22:37:14\u001b[0m | \u001b[36mautotrain.trainers.clm.utils\u001b[0m:\u001b[36mpost_training_steps\u001b[0m:\u001b[36m287\u001b[0m - \u001b[1mFinished training, saving model...\u001b[0m\n","/usr/local/lib/python3.10/dist-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n","  warnings.warn(\n","\u001b[1mINFO    \u001b[0m | \u001b[32m2024-06-07 22:37:14\u001b[0m | \u001b[36mautotrain.trainers.clm.utils\u001b[0m:\u001b[36mpost_training_steps\u001b[0m:\u001b[36m317\u001b[0m - \u001b[1mPushing model to hub...\u001b[0m\n","adapter_model.safetensors:   0% 0.00/27.3M [00:00<?, ?B/s]\n","tokenizer.model:   0% 0.00/493k [00:00<?, ?B/s]\u001b[A\n","\n","training_args.bin:   0% 0.00/5.11k [00:00<?, ?B/s]\u001b[A\u001b[A\n","\n","\n","Upload 3 LFS files:   0% 0/3 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\n","\n","adapter_model.safetensors:   0% 16.4k/27.3M [00:00<04:20, 104kB/s]\n","training_args.bin: 100% 5.11k/5.11k [00:00<00:00, 17.9kB/s]\n","tokenizer.model: 100% 493k/493k [00:00<00:00, 764kB/s]  \n","adapter_model.safetensors: 100% 27.3M/27.3M [00:02<00:00, 11.9MB/s]\n","\n","\n","\n","Upload 3 LFS files: 100% 3/3 [00:02<00:00,  1.16it/s]\n","\u001b[1mINFO    \u001b[0m | \u001b[32m2024-06-07 22:37:20\u001b[0m | \u001b[36mautotrain.cli.run_llm\u001b[0m:\u001b[36mrun\u001b[0m:\u001b[36m350\u001b[0m - \u001b[1mJob ID: 7302\u001b[0m\n"]}]},{"cell_type":"code","source":["\n","!autotrain llm -h"],"metadata":{"id":"AYcNlpG0gzLy","executionInfo":{"status":"ok","timestamp":1717799873353,"user_tz":300,"elapsed":7522,"user":{"displayName":"Koushik M","userId":"16400000590471005233"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"816c11cf-f64e-4202-b8d5-42b2b070b0fc"},"execution_count":25,"outputs":[{"output_type":"stream","name":"stdout","text":["usage: autotrain <command> [<args>] llm [-h] [--train] [--deploy] [--inference]\n","                                        [--username USERNAME]\n","                                        [--backend {spaces-a10g-large,spaces-a10g-small,spaces-a100-large,spaces-t4-medium,spaces-t4-small,spaces-cpu-upgrade,spaces-cpu-basic,spaces-l4x1,spaces-l4x4,spaces-a10g-largex2,spaces-a10g-largex4,dgx-a100,dgx-2a100,dgx-4a100,dgx-8a100,ep-aws-useast1-s,ep-aws-useast1-m,ep-aws-useast1-l,ep-aws-useast1-xl,ep-aws-useast1-2xl,ep-aws-useast1-4xl,ep-aws-useast1-8xl,nvcf-l40sx1,nvcf-h100x1,nvcf-h100x2,nvcf-h100x4,nvcf-h100x8,local-ui,local,local-cli}]\n","                                        [--token TOKEN] [--push-to-hub] --model MODEL\n","                                        --project-name PROJECT_NAME [--data-path DATA_PATH]\n","                                        [--train-split TRAIN_SPLIT] [--valid-split VALID_SPLIT]\n","                                        [--batch-size BATCH_SIZE] [--seed SEED] [--epochs EPOCHS]\n","                                        [--gradient-accumulation GRADIENT_ACCUMULATION]\n","                                        [--disable-gradient-checkpointing] [--lr LR]\n","                                        [--log {none,wandb,tensorboard}]\n","                                        [--text_column TEXT_COLUMN]\n","                                        [--rejected_text_column REJECTED_TEXT_COLUMN]\n","                                        [--prompt_text_column PROMPT_TEXT_COLUMN]\n","                                        [--model-ref MODEL_REF] [--warmup_ratio WARMUP_RATIO]\n","                                        [--optimizer OPTIMIZER] [--scheduler SCHEDULER]\n","                                        [--weight_decay WEIGHT_DECAY]\n","                                        [--max_grad_norm MAX_GRAD_NORM] [--add_eos_token]\n","                                        [--block_size BLOCK_SIZE] [--peft] [--lora_r LORA_R]\n","                                        [--lora_alpha LORA_ALPHA] [--lora_dropout LORA_DROPOUT]\n","                                        [--logging_steps LOGGING_STEPS]\n","                                        [--evaluation_strategy {epoch,steps,no}]\n","                                        [--save_total_limit SAVE_TOTAL_LIMIT]\n","                                        [--auto_find_batch_size]\n","                                        [--mixed_precision {fp16,bf16,None}]\n","                                        [--quantization {int4,int8,None}]\n","                                        [--model_max_length MODEL_MAX_LENGTH]\n","                                        [--max_prompt_length MAX_PROMPT_LENGTH]\n","                                        [--max_completion_length MAX_COMPLETION_LENGTH]\n","                                        [--trainer {default,dpo,sft,orpo,reward}]\n","                                        [--target_modules TARGET_MODULES] [--merge_adapter]\n","                                        [--use_flash_attention_2] [--dpo-beta DPO_BETA]\n","                                        [--chat_template {tokenizer,chatml,zephyr,None}]\n","                                        [--padding {left,right,None}]\n","\n","✨ Run AutoTrain LLM\n","\n","options:\n","  -h, --help            show this help message and exit\n","  --train               Command to train the model\n","  --deploy              Command to deploy the model (limited availability)\n","  --inference           Command to run inference (limited availability)\n","  --username USERNAME   Hugging Face Hub Username\n","  --backend {spaces-a10g-large,spaces-a10g-small,spaces-a100-large,spaces-t4-medium,spaces-t4-small,spaces-cpu-upgrade,spaces-cpu-basic,spaces-l4x1,spaces-l4x4,spaces-a10g-largex2,spaces-a10g-largex4,dgx-a100,dgx-2a100,dgx-4a100,dgx-8a100,ep-aws-useast1-s,ep-aws-useast1-m,ep-aws-useast1-l,ep-aws-useast1-xl,ep-aws-useast1-2xl,ep-aws-useast1-4xl,ep-aws-useast1-8xl,nvcf-l40sx1,nvcf-h100x1,nvcf-h100x2,nvcf-h100x4,nvcf-h100x8,local-ui,local,local-cli}\n","                        Backend to use: default or spaces. Spaces backend requires push_to_hub &\n","                        username. Advanced users only.\n","  --token TOKEN         Your Hugging Face API token. Token must have write access to the model\n","                        hub.\n","  --push-to-hub         Push to hub after training will push the trained model to the Hugging Face\n","                        model hub.\n","  --model MODEL         Base model to use for training\n","  --project-name PROJECT_NAME\n","                        Output directory / repo id for trained model (must be unique on hub)\n","  --data-path DATA_PATH\n","                        Train dataset to use. When using cli, this should be a directory path\n","                        containing training and validation data in appropriate formats\n","  --train-split TRAIN_SPLIT\n","                        Train dataset split to use\n","  --valid-split VALID_SPLIT\n","                        Validation dataset split to use\n","  --batch-size BATCH_SIZE, --train-batch-size BATCH_SIZE\n","                        Training batch size to use\n","  --seed SEED           Random seed for reproducibility\n","  --epochs EPOCHS       Number of training epochs\n","  --gradient-accumulation GRADIENT_ACCUMULATION, --gradient-accumulation GRADIENT_ACCUMULATION\n","                        Gradient accumulation steps\n","  --disable-gradient-checkpointing, --disable-gradient-checkpointing, --disable-gc\n","                        Disable gradient checkpointing\n","  --lr LR               Learning rate\n","  --log {none,wandb,tensorboard}\n","                        Use experiment tracking\n","  --text_column TEXT_COLUMN, --text-column TEXT_COLUMN\n","                        Specify the dataset column to use for text data. This parameter is\n","                        essential for models processing textual information. Default is 'text'.\n","  --rejected_text_column REJECTED_TEXT_COLUMN, --rejected-text-column REJECTED_TEXT_COLUMN\n","                        Define the column to use for storing rejected text entries, which are\n","                        typically entries that do not meet certain criteria for processing.\n","                        Default is 'rejected'. Used only for orpo, dpo and reward trainerss\n","  --prompt_text_column PROMPT_TEXT_COLUMN, --prompt-text-column PROMPT_TEXT_COLUMN\n","                        Identify the column that contains prompt text for tasks requiring\n","                        contextual inputs, such as conversation or completion generation. Default\n","                        is 'prompt'. Used only for dpo trainer\n","  --model-ref MODEL_REF, --model-ref MODEL_REF\n","                        Reference model to use for DPO when not using PEFT\n","  --warmup_ratio WARMUP_RATIO, --warmup-ratio WARMUP_RATIO\n","                        Set the proportion of training allocated to warming up the learning rate,\n","                        which can enhance model stability and performance at the start of\n","                        training. Default is 0.1\n","  --optimizer OPTIMIZER\n","                        Choose the optimizer algorithm for training the model. Different\n","                        optimizers can affect the training speed and model performance.\n","                        'adamw_torch' is used by default.\n","  --scheduler SCHEDULER\n","                        Select the learning rate scheduler to adjust the learning rate based on\n","                        the number of epochs. 'linear' decreases the learning rate linearly from\n","                        the initial lr set. Default is 'linear'. Try 'cosine' for a cosine\n","                        annealing schedule.\n","  --weight_decay WEIGHT_DECAY, --weight-decay WEIGHT_DECAY\n","                        Define the weight decay rate for regularization, which helps prevent\n","                        overfitting by penalizing larger weights. Default is 0.0\n","  --max_grad_norm MAX_GRAD_NORM, --max-grad-norm MAX_GRAD_NORM\n","                        Set the maximum norm for gradient clipping, which is critical for\n","                        preventing gradients from exploding during backpropagation. Default is\n","                        1.0.\n","  --add_eos_token, --add-eos-token\n","                        Toggle whether to automatically add an End Of Sentence (EOS) token at the\n","                        end of texts, which can be critical for certain types of models like\n","                        language models. Only used for `default` trainer\n","  --block_size BLOCK_SIZE, --block-size BLOCK_SIZE\n","                        Specify the block size for processing sequences. This is maximum sequence\n","                        length or length of one block of text. Setting to -1 determines block size\n","                        automatically. Default is -1.\n","  --peft, --use-peft    Enable LoRA-PEFT\n","  --lora_r LORA_R, --lora-r LORA_R\n","                        Set the 'r' parameter for Low-Rank Adaptation (LoRA). Default is 16.\n","  --lora_alpha LORA_ALPHA, --lora-alpha LORA_ALPHA\n","                        Specify the 'alpha' parameter for LoRA. Default is 32.\n","  --lora_dropout LORA_DROPOUT, --lora-dropout LORA_DROPOUT\n","                        Set the dropout rate within the LoRA layers to help prevent overfitting\n","                        during adaptation. Default is 0.05.\n","  --logging_steps LOGGING_STEPS, --logging-steps LOGGING_STEPS\n","                        Determine how often to log training progress in terms of steps. Setting it\n","                        to '-1' determines logging steps automatically.\n","  --evaluation_strategy {epoch,steps,no}, --evaluation-strategy {epoch,steps,no}\n","                        Choose how frequently to evaluate the model's performance, with 'epoch' as\n","                        the default, meaning at the end of each training epoch\n","  --save_total_limit SAVE_TOTAL_LIMIT, --save-total-limit SAVE_TOTAL_LIMIT\n","                        Limit the total number of saved model checkpoints to manage disk usage\n","                        effectively. Default is to save only the latest checkpoint\n","  --auto_find_batch_size, --auto-find-batch-size\n","                        Automatically determine the optimal batch size based on system\n","                        capabilities to maximize efficiency.\n","  --mixed_precision {fp16,bf16,None}, --mixed-precision {fp16,bf16,None}\n","                        Choose the precision mode for training to optimize performance and memory\n","                        usage. Options are 'fp16', 'bf16', or None for default precision. Default\n","                        is None.\n","  --quantization {int4,int8,None}, --quantization {int4,int8,None}\n","                        Choose the quantization level to reduce model size and potentially\n","                        increase inference speed. Options include 'int4', 'int8', or None.\n","                        Enabling requires --peft\n","  --model_max_length MODEL_MAX_LENGTH, --model-max-length MODEL_MAX_LENGTH\n","                        Set the maximum length for the model to process in a single batch, which\n","                        can affect both performance and memory usage. Default is 1024\n","  --max_prompt_length MAX_PROMPT_LENGTH, --max-prompt-length MAX_PROMPT_LENGTH\n","                        Specify the maximum length for prompts used in training, particularly\n","                        relevant for tasks requiring initial contextual input. Used only for\n","                        `orpo` trainer.\n","  --max_completion_length MAX_COMPLETION_LENGTH, --max-completion-length MAX_COMPLETION_LENGTH\n","                        Completion length to use, for orpo: encoder-decoder models only\n","  --trainer {default,dpo,sft,orpo,reward}\n","                        Trainer type to use\n","  --target_modules TARGET_MODULES, --target-modules TARGET_MODULES\n","                        Identify specific modules within the model architecture to target with\n","                        adaptations or optimizations, such as LoRA. Comma separated list of module\n","                        names. Default is 'all-linear'.\n","  --merge_adapter, --merge-adapter\n","                        Use this flag to merge PEFT adapter with the model\n","  --use_flash_attention_2, --use-flash-attention-2, --use-fa2\n","                        Use flash attention 2\n","  --dpo-beta DPO_BETA, --dpo-beta DPO_BETA\n","                        Beta for DPO trainer\n","  --chat_template {tokenizer,chatml,zephyr,None}, --chat-template {tokenizer,chatml,zephyr,None}\n","                        Apply a specific template for chat-based interactions, with options\n","                        including 'tokenizer', 'chatml', 'zephyr', or None. This setting can shape\n","                        the model's conversational behavior.\n","  --padding {left,right,None}, --padding {left,right,None}\n","                        Specify the padding direction for sequences, critical for models sensitive\n","                        to input alignment. Options include 'left', 'right', or None\n"]}]},{"cell_type":"code","source":["!pip install -q safetensors"],"metadata":{"id":"k7FXK6LfhOTy","executionInfo":{"status":"ok","timestamp":1717799885638,"user_tz":300,"elapsed":7463,"user":{"displayName":"Koushik M","userId":"16400000590471005233"}}},"execution_count":26,"outputs":[]},{"cell_type":"code","source":["import torch\n","from peft import PeftModel\n","from transformers import AutoModelForCausalLM, AutoTokenizer\n","\n","model_name = \"mistralai/Mistral-7B-Instruct-v0.1\"\n","#adapters_name = \"1littlecoder/mistral-7b-mj-finetune\"\n","\n","device = \"cuda\" # the device to load the model onto\n","\n","model = AutoModelForCausalLM.from_pretrained(\n","    model_name,\n","   # load_in_4bit=True,\n","    torch_dtype=torch.bfloat16,\n","    device_map='auto'\n",")\n","##model = PeftModel.from_pretrained(model, adapters_name)\n","#model = model.merge_and_unload()\n","tokenizer = AutoTokenizer.from_pretrained(model_name)\n","tokenizer.bos_token_id = 1\n","\n","stop_token_ids = [0]\n","\n","print(f\"Successfully loaded the model {model_name} into memory\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":188,"referenced_widgets":["ab31969c3a01454caec8b1e2239fc1b4","a6dcdea3b6b1424f8be58c287e72f835","4c41f17942094a9d9605a76c8cc98e71","ebb788b4002145a99407ae3ef74aa72c","39edb26205bf4fa29a9fb031d7e9033b","3ff005d78fc94262a2278ef77d444ed6","eeb6b759967d4566876ec2e13c7deaa1","d34036ca2b574762a2f084c1d00e3773","0a8b26bcde964de9837a9502110ba725","f006930afe4e46b8b8e9df87f296928e","ae2e01665211437188c8bc99d98c4ef6"]},"id":"FYa8FFEehUnb","executionInfo":{"status":"ok","timestamp":1717799977307,"user_tz":300,"elapsed":65922,"user":{"displayName":"Koushik M","userId":"16400000590471005233"}},"outputId":"995341ea-1434-486a-cdeb-d79c2a466cc9"},"execution_count":27,"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_token.py:89: UserWarning: \n","The secret `HF_TOKEN` does not exist in your Colab secrets.\n","To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n","You will be able to reuse this secret in all of your notebooks.\n","Please note that authentication is recommended but still optional to access public models or datasets.\n","  warnings.warn(\n"]},{"output_type":"display_data","data":{"text/plain":["Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"ab31969c3a01454caec8b1e2239fc1b4"}},"metadata":{}},{"output_type":"stream","name":"stderr","text":["WARNING:root:Some parameters are on the meta device device because they were offloaded to the cpu.\n"]},{"output_type":"stream","name":"stdout","text":["Successfully loaded the model mistralai/Mistral-7B-Instruct-v0.1 into memory\n"]}]},{"cell_type":"code","source":[],"metadata":{"id":"i5FD_e89hb6y"},"execution_count":null,"outputs":[]}]}